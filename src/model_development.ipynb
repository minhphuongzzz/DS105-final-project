{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-development.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfA7_mdBCD9c"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmpwKOXiB8L9"
      },
      "source": [
        "import folium\n",
        "import json\n",
        "from folium import plugins\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import f_oneway\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from IPython.display import clear_output\n",
        "import scipy as sp\n",
        "import scipy.sparse\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler,MaxAbsScaler,RobustScaler, MinMaxScaler,FunctionTransformer, maxabs_scale\n",
        "from sklearn.metrics import classification_report,confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix, plot_confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE,ADASYN\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN7IAjN0nL8L"
      },
      "source": [
        "# **Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXitthIfntL1"
      },
      "source": [
        "# FUNCTION FOR PREPROCESSING\n",
        "\n",
        "# Group classes in landslide_size\n",
        "def combine_landslide_size(df_size):\n",
        "  df_size.replace(to_replace=['catastrophic'], value='very_large', inplace=True)\n",
        "  return df_size\n",
        "\n",
        "# Combine features with high correlation\n",
        "def combine_features(df, list_features):\n",
        "  return df[list_features].mean(axis=1)\n",
        "\n",
        "# Combine text description columns\n",
        "def combine_descriptions(df, description_columns):\n",
        "  df['event_description'].fillna('', inplace=True)\n",
        "  df['description'] = ''\n",
        "  for col in description_columns:\n",
        "    df['description'] = df['description'] + df[col] + \" \"\n",
        "  return df['description']\n",
        "\n",
        "# Combine soil columns into one column\n",
        "def combine_soils(df, soil_columns):\n",
        "  df_soil = df[soil_columns]\n",
        "  for i in range(df_soil.shape[0]):\n",
        "    df_soil.loc[i, 'soil'] = df_soil.loc[i, soil_columns].mode()[0]\n",
        "  return df_soil['soil']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE9bhoLjnaHV"
      },
      "source": [
        "# PREPROCESSING FUNCTION\n",
        "\n",
        "def preprocessing(df):\n",
        "\n",
        "  # Combine landslide_size\n",
        "  df['landslide_size'] = combine_landslide_size(df['landslide_size'])\n",
        "\n",
        "  # Combine features with high correlation\n",
        "  population_columns = ['population_density_2000', 'population_density_2005', 'population_density_2010', 'population_density_2015', 'population_density_2020']\n",
        "  dew_temp_avg_columns = ['dew', 'feelslikemin', 'feelslikemax', 'feelslike', 'tempmin', 'tempmax', 'temp']\n",
        "  df['population_density_avg'] = combine_features(df, population_columns)\n",
        "  df['dew_temp_avg'] = combine_features(df, dew_temp_avg_columns)\n",
        "\n",
        "  # Combine description columns\n",
        "  description_columns = ['event_description', 'event_title', 'location_description']\n",
        "  df['description'] = combine_descriptions(df, description_columns)\n",
        "\n",
        "  # Combine 'soil_texture_'\n",
        "  soil_columns = ['soil_texture_0', 'soil_texture_10', 'soil_texture_30', 'soil_texture_60', 'soil_texture_100', 'soil_texture_200']\n",
        "  df['soil_texture'] = combine_soils(df, soil_columns)\n",
        "\n",
        "  # Drop old columns\n",
        "  df.drop(set.union(set(population_columns), set(dew_temp_avg_columns), set(description_columns), set(soil_columns)), axis=1, inplace=True)\n",
        "  df.drop('stations', axis=1, inplace=True) \n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZcqGu3jdHEB"
      },
      "source": [
        "# FUNCTIONS FOR FEATURE SELECTION\n",
        "\n",
        "# Chi-square: categorical features and target\n",
        "def chisquare(df, cate_cols):\n",
        "\n",
        "  df_cate = df[cate_cols].apply(LabelEncoder().fit_transform)\n",
        "  X = df_cate.drop('landslide_size', axis=1)\n",
        "  y = df_cate['landslide_size']\n",
        "  selector = SelectKBest(chi2, k = 'all')\n",
        "  X_new = selector.fit_transform(X, y)\n",
        "  names = X.columns.values[selector.get_support()]\n",
        "  scores = selector.scores_[selector.get_support()]\n",
        "  p_values = selector.pvalues_[selector.get_support()]\n",
        "  name_score_p = list(zip(names, scores, p_values))\n",
        "  df_chi2 = pd.DataFrame(data = name_score_p, columns=['Column name', 'Chi-square', 'P-values'])\n",
        "  df_chi2 = df_chi2.sort_values(['Chi-square', 'Column name'], ascending = [False, True]).reset_index(drop=True)\n",
        "\n",
        "  return df_chi2\n",
        "\n",
        "# ANOVA: numerical features and target\n",
        "def anova(df, num_cols):\n",
        "\n",
        "  df_num = df[num_cols]\n",
        "  df_num['event_date'] = df_num['event_date'].astype(int)\n",
        "  clear_output()\n",
        "  X = df_num\n",
        "  y = df['landslide_size']\n",
        "  X_array = X.values\n",
        "  y_array = LabelEncoder().fit_transform(y)\n",
        "  selector = SelectKBest(f_classif, k = 'all')\n",
        "  X_new = selector.fit_transform(X_array, y_array)\n",
        "  names = X.columns.values[selector.get_support()]\n",
        "  scores = selector.scores_[selector.get_support()]\n",
        "  p_values = selector.pvalues_[selector.get_support()]\n",
        "  name_score_p = list(zip(names, scores, p_values))\n",
        "  df_anova = pd.DataFrame(data = name_score_p, columns=['Column name', 'F-Scores', 'P-values'])\n",
        "  df_anova = df_anova.sort_values(['F-Scores', 'Column name'], ascending = [False, True]).reset_index(drop=True)\n",
        "\n",
        "  return df_anova"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd7s0eYivx8S"
      },
      "source": [
        "# FEATURE SELECTION FUNCTION\n",
        "\n",
        "def feature_selection(df, num_threshold, cate_threshold):\n",
        "\n",
        "  cate_cols = df.select_dtypes('object').columns\n",
        "  num_cols = df.select_dtypes(exclude='object').columns\n",
        "\n",
        "  df_chi2 = chisquare(df, cate_cols)\n",
        "  df_anova = anova(df, num_cols)\n",
        "\n",
        "  cate_cols_used = df_chi2.loc[:cate_threshold, 'Column name']\n",
        "  num_cols_used = df_anova.loc[:num_threshold, 'Column name']\n",
        "\n",
        "  columns_used = list(set.union(set(cate_cols_used), set(num_cols_used)))\n",
        "\n",
        "  return columns_used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-8uhRNnw58n"
      },
      "source": [
        "# FEATURE ENGINEERING FUNCTION\n",
        "\n",
        "def feature_engineering(X, y):\n",
        "\n",
        "  # Convert datetime to integer\n",
        "  X['event_date'] = X['event_date'].astype('int')\n",
        "\n",
        "  # One-hot Encoding for categorical features (except 'description' column)\n",
        "  cate_cols = [i for i in X.columns if(X[i].dtype=='object' and i!='description')]\n",
        "  X = pd.get_dummies(X, columns = cate_cols)\n",
        "\n",
        "  # Split train-test set\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "  # TFIDF transform 'description' column\n",
        "  vec = TfidfVectorizer(ngram_range=(1, 2), analyzer='word')\n",
        "  text_train_vec = vec.fit_transform(X_train['description'])\n",
        "  text_test_vec = vec.transform(X_test['description'])\n",
        "\n",
        "  X_train.drop(['description'], axis=1, inplace=True)\n",
        "  X_test.drop(['description'], axis=1, inplace=True)\n",
        "\n",
        "  X_train = sp.sparse.hstack([text_train_vec, X_train]) \n",
        "  X_test = sp.sparse.hstack([text_test_vec, X_test]) \n",
        "\n",
        "  # Scale features\n",
        "  scaler = MaxAbsScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjAoc_v44Tlz"
      },
      "source": [
        "# OVERSAMPLING FOR IMBALANCED CLASSES\n",
        "\n",
        "def oversampling(X_train, y_train):\n",
        "\n",
        "  oversampling_techique = ADASYN()\n",
        "  X_train_os, y_train_os = oversampling_techique.fit_resample(X_train, y_train)\n",
        "\n",
        "  return X_train_os, y_train_os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa7kIHK4zhD2"
      },
      "source": [
        "# MODEL DEVELOPMENT FUNCTION\n",
        "\n",
        "def model_development(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  df_score = pd.DataFrame({'model': [], 'accuracy': [], 'f1-macro': []})\n",
        "  \n",
        "  classifiers = [RandomForestClassifier(random_state=42), \n",
        "                 PassiveAggressiveClassifier(random_state=42), \n",
        "                 LogisticRegression(max_iter=500, random_state=42), \n",
        "                 SVC(random_state=42)]\n",
        "\n",
        "  for classifier in classifiers:\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    df_score = df_score.append({'model': str(classifier), 'accuracy': accuracy_score(y_pred, y_test), 'f1-macro': f1_score(y_test, y_pred, average=\"macro\")}, ignore_index=True)\n",
        "\n",
        "  return df_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUZeIjBptYYB"
      },
      "source": [
        "# LANDSLIDE SIZE CLASSIFICATION FUNCTION\n",
        "\n",
        "def size_classification(df, num_threshold, cate_threshold, isOversampled):\n",
        "\n",
        "  # Additional preprocessing \n",
        "  df = preprocessing(df)\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  # Select features for model\n",
        "  features_selected = feature_selection(df, num_threshold, cate_threshold)\n",
        "\n",
        "  # Access independent and dependent features\n",
        "  X = df[features_selected]\n",
        "  y = df['landslide_size']\n",
        "\n",
        "  # Feature engineering\n",
        "  X_train, X_test, y_train, y_test = feature_engineering(X, y)\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  # Oversampling for imbalanced classes\n",
        "  if isOversampled:\n",
        "    X_train, y_train = oversampling(X_train, y_train)\n",
        "\n",
        "  result = model_development(X_train, X_test, y_train, y_test)\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nvqpwNJ4N41"
      },
      "source": [
        "# **Implement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yirSqA80g_Pl"
      },
      "source": [
        "## **Before oversampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "DUig-dBzGwTr",
        "outputId": "ecbf62c6-63b1-4591-ecdf-b9232dd67ba0"
      },
      "source": [
        "df = pd.read_csv('/content/GLC_features_preprocessed.csv', parse_dates=['event_date'], na_filter= False)\n",
        "\n",
        "result = size_classification(df, 15, 8, 0)\n",
        "\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1-macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.713623</td>\n",
              "      <td>0.481892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PassiveAggressiveClassifier(random_state=42)</td>\n",
              "      <td>0.715407</td>\n",
              "      <td>0.519439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
              "      <td>0.718973</td>\n",
              "      <td>0.511298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.717190</td>\n",
              "      <td>0.472977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               model  accuracy  f1-macro\n",
              "0            RandomForestClassifier(random_state=42)  0.713623  0.481892\n",
              "1       PassiveAggressiveClassifier(random_state=42)  0.715407  0.519439\n",
              "2  LogisticRegression(max_iter=500, random_state=42)  0.718973  0.511298\n",
              "3                               SVC(random_state=42)  0.717190  0.472977"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uHtKKAKhEnF"
      },
      "source": [
        "## **After oversampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "W2VNC8V9LfOD",
        "outputId": "02676866-f2d2-4320-fffe-77489185ff4c"
      },
      "source": [
        "df = pd.read_csv('/content/GLC_features_preprocessed.csv', parse_dates=['event_date'], na_filter= False)\n",
        "\n",
        "result = size_classification(df, 15, 8, 1)\n",
        "\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1-macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.716476</td>\n",
              "      <td>0.498321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PassiveAggressiveClassifier(random_state=42)</td>\n",
              "      <td>0.711484</td>\n",
              "      <td>0.520779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
              "      <td>0.715050</td>\n",
              "      <td>0.521931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.706847</td>\n",
              "      <td>0.477818</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               model  accuracy  f1-macro\n",
              "0            RandomForestClassifier(random_state=42)  0.716476  0.498321\n",
              "1       PassiveAggressiveClassifier(random_state=42)  0.711484  0.520779\n",
              "2  LogisticRegression(max_iter=500, random_state=42)  0.715050  0.521931\n",
              "3                               SVC(random_state=42)  0.706847  0.477818"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCIyE0mqhG8X"
      },
      "source": [
        "## **GridSearch for Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN9e6jTHhLww",
        "outputId": "1b515f3d-acf4-49ab-fe10-07e90c194094"
      },
      "source": [
        "df = pd.read_csv('/content/GLC_features_preprocessed.csv', parse_dates=['event_date'], na_filter= False)\n",
        "\n",
        "# Additional preprocessing \n",
        "df = preprocessing(df)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# Select features for model\n",
        "features_selected = feature_selection(df, 15, 8)\n",
        "\n",
        "# Access independent and dependent features\n",
        "X = df[features_selected]\n",
        "y = df['landslide_size']\n",
        "\n",
        "# Feature engineering\n",
        "X_train, X_test, y_train, y_test = feature_engineering(X, y)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# Oversampling for imbalanced classes\n",
        "X_train, y_train = oversampling(X_train, y_train)\n",
        "\n",
        "grid = {\"C\": np.logspace(-3,3,7), \"penalty\": [\"l1\",\"l2\"]}\n",
        "logreg = LogisticRegression()\n",
        "logreg_cv = GridSearchCV(logreg, grid, cv=10)\n",
        "\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "y_pred = logreg_cv.predict(X_test)\n",
        "\n",
        "accuracy_score(y_pred, y_test), f1_score(y_test, y_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7171897289586305, 0.5225880890952899)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}